\inputdir{miss}

The missing data problem is probably the simplest to understand and
interpret results.  
We  begin by binning our data onto a regular mesh.
For $\mathbf{L}$ in fitting goals (\ref{eq:geophysics}) we will use a selector 
matrix $\mathbf{J}$,
which is `1' at locations where we have data and `0' at unknown locations.
As an  example, let's  try to interpolate 
a day's worth of  data
collected by SeaBeam (Figure~\ref{fig:init}), which measures
water depth under and to the side of a  ship \cite[]{gee}. 

\sideplot{init}{width=3.0in,height=3.0in}{Depth of the ocean under ship tracks.}

Figure~\ref{fig:pef} shows the result of estimating a PEF from the
known data locations and then using it to interpolate the entire mesh.
Note how the solution has a lower spatial frequency as we move away from
the recorded data. In addition, the original tracks of the ship are still
clearly visible.  

\sideplot{pef}{width=3.0in,height=3.0in}{Result of using a PEF to
interpolate Figure~\ref{fig:init}, taken from GEE.}

\par
If we look at a histograms of the known data and our estimated data we
can see the effect of the PEF.  The histogram of the known data has a
nice Gaussian shape.  The predicted
data is much less Gaussian with a much lower variance.  We want estimated 
data to have the same statistical properties as the known data (for
a Gaussian distribution this means matching the mean and variance).

\sideplot{histo}{width=3.0in,height=3.0in}{Histogram for the known data 
(solid lines) and the estimated data (`*').  Note the dissimilar
shapes.}

\par
Geostatisticians are confronted with the same problem. They can produce
smooth, low frequency models through kriging, but must add a little
twist to get model with the statistical properties as the data.
To understand how, a brief review of kriging is necessary.
Kriging estimates each model point by a linear combination of nearby data 
points. For simplicity lets assume that the data has a standard
normal distribution.
The geostatistician find all of the points $m_1 .... m_n$ around the point they
are trying to estimate $m_0$. The vector distance between all data points
$\mathbf{d}_{ij}$
and each data point and the estimation point $\mathbf{d}_{i0}$ are then computed.
Using the predefined covariance function estimate $C$, a covariance
value is then extracted
between all known point pairs $C_{ij}$ and
between known points and
estimation point $C_{i0}$ at the given distances $\mathbf{d}_{ij}$  and
$\mathbf{d}_{i0}$   (Figure~\ref{fig:covar-def}).
They compute the weights   ($w_1 ... w_n$) by solving the set
of equations implied by
\begin{equation}
\left[
\begin{array}{cccc}
C_{11}  &...& C_{1n} & 1 \\
.  &...& . & . \\
.  &...& . & . \\
.  &...& . & . \\
C_{n1}  &...& C_{nn} &  1 \\
1 &...& 1 & 0
\end{array}
\right]
\left[
\begin{array}{c}
w_1 \\
. \\
. \\
. \\
w_n \\
\mu
\end{array}
\right]
=
\left[
\begin{array}{c}
C_{10} \\
. \\
. \\
. \\
C_{n0} \\
1
\end{array} \label{eq:krig}
\right] .
\end{equation}
Estimating $m_0$ is then simply,
\beq
m_0= \sum_{i=1}^{n} w_i m_i.
\eeq
To guarantee that the matrix in equation (\ref{eq:krig})
is invertible geostatisticians approximate
the covariance function
through a linear combination of a limited set of
functions that guarantee that the matrix in equation (\ref{eq:krig}) is
positive-definite and therefore invertible.
% minimizes the variance of 
%Kirgging  models tend to have the same
%low spatial frequency problems we see in the geophysic's 
%approach (Figure~\ref{fig:sea.pef}).

\inputdir{XFig}
\plot{covar-def}{width=6.0in,height=3.0in}{Definition of the terms
in equation (\ref{eq:krig}). A vector is drawn between two points.  The covariance
at the angle and distance describing the vector is then selected.}
\inputdir{miss}

The smooth models provided by kriging  often prove
to be poor representations of earth properties.
A classic example is fluid flow where kriged models  tend to give inaccurate
predictions. The geostatistical solution
is to perform Gaussian stochastic simulation, rather than kriging, to
estimate the field \cite[]{geostat2}.
There are two major  differences between kriging and simulation. 
The primary difference
is that a random component is introduced into the estimation process.   
Stochastic simulation, or  sequential Gaussian simulation, begins
with a random point being selected in the model space.
They then perform kriging, obtaining
a kriged value $m_0$ and  a kriging variance $\sigma_k$.
Instead of using $m_0$ for the model value we
select a  random number $\beta$
from a  normal distribution.
We use as our model point estimate $m_i$,
\beq
m_i = m_0 + \sigma_k \beta.
\eeq
We then select a new point in the model space and repeat the procedure.
To preserve spatial variability,  a second change is made: 
all the previously estimated points are treated as `data' when estimating
new points guaranteeing that the model matches the covariance estimate. 
By selecting different random numbers (and/or visiting model points
in a different order)  we will get a different, equiprobable model
estimate.
The advantage of the models estimated through simulation is that they
have not only the covariance of they data, but also the variance.
As a result the models estimated by simulation
give more realistic fluid flow measurements compared to a kriged model.
In addition, by trying different realizations fluid flow variability
can be assessed.
\par
%
%In geophysics we can get a measure of something akin to error
%variance by looking at the residual at known data locations
%
%
% Much more difficult with more complex operators (we do not 
% have the luxury of having known locations)
%
%
%
%
%
%
The difference between kriging and simulation has a corollary in our
least squares estimation problem. To see how let's write
our fitting goals in a slightly different format,
\beqa
\bf r_d \pox \mathbf{d}  - \mathbf{J}  \mathbf{m}  \nonumber \\ 
\bf r_m \pox \epsilon \reg \mathbf{m}\label{eq:rbar},
\eeqa
where $\mathbf{r}_d$ is our data residual and $\mathbf{r}_m$ is our model
residual.  The model residual is the result of applying our
covariance estimate $\reg$ to our model estimate.  The larger
the value of a given $\mathbf{r}_m$, the less that model point makes
sense with its surrounding points, given our idea of covariance.
This is similar to kriging variance.
It follows that we might be able to obtain something similar
to the geostatistician's simulations by rewriting our fitting
goals as 
\beqa
\mathbf{d} \pox  \mathbf{J}  \mathbf{m}  \nonumber \\ 
\sigma \mathbf{v} \pox \epsilon \reg \mathbf{m}\label{eq:rand},
\eeqa
where $\mathbf{v}$ is a vector of random normal numbers and $\sigma$ is 
a measure of our estimation uncertainty\footnote{For the missing
data problem $\epsilon$ could be used exclusively.
As  our data fitting goal becomes more complex,
having a separate  $\sigma$ and $\epsilon$ becomes useful.}.

By adjusting $\sigma$
we can change the distribution of
$\mathbf{m}$. For example, let's return to the SeaBeam example.
Figure~\ref{fig:distrib} shows four different model estimations
using a normal distribution and various values for the variance.
Note how the texture of the model changes significantly. If we look
at a histogram of the various realizations (Figure~\ref{fig:distir}),
we see that the correct
distribution is somewhere between our second and third realization.
\par 
We can get an estimate of $\sigma$, or in the case of the missing
data problem $\frac{\sigma}{\epsilon}$, by applying fitting goals 
(\ref{eq:rbar}). If we look at the variance of the model residual $\sigma(\mathbf{m}_r)$  and 
$\sigma(\mathbf{d})$ we can get a good estimate of $\sigma$,
\beq
\sigma = \frac{ \sigma(\mathbf{r}_m) }{ \sigma(\mathbf{d})} \label{eq:sigma.calc} .
\eeq

%At this stage my method for choosing
%$\sigma$ is more guess work than science. The general range of
%$\sigma$, for the missing data problem, can be found by looking at
%the model residuals using $\sigma=0$. An acceptable $\sigma$ is usually
%within a factor of two of the median absolute value of the residuals
%at `known' model locations.  
%
%Choosing an acceptable value of $\sigma$ is sh
%Using the same normal score transform common in geostatistics we
%could emulate any distribution.

\plot{distrib}{width=6in,height=4.5in}{Four different realizations
with increasing $\sigma$  in fitting goals (\ref{eq:rand}).}

\sideplot{distir}{width=3.0in,height=3.0in}{Histogram of
the known data (solid line) and the four different realizations of
Figure~\ref{fig:distrib}.}
\par 
Figure \ref{fig:movie} shows eight different realizations with a
random noise level calculated through equation (\ref{eq:sigma.calc}).
Note how we have done a good job emulating the
distribution of the known data. Each image shows some similar
features but also significant differences (especially note
within the `V' portion of the known data).
\par


\plot{movie}{width=6.0in,height=8.0in}{
Eight different realizations of the SeaBeam interpolation problem and
their histograms. 
Note how the realizations  vary away from the known data points.  }

A potentially attractive feature of setting up the problem in this
manner is that it easy to have both  a space-varying covariance function
(a steering filter or non-stationary PEF) along with a non-stationary
variance. Figure~\ref{fig:non-stat} shows the SeaBeam example
again with the variance increasing from left to right.

\sideplot{non-stat}{width=2.5in,height=2.5in}{Realization where
the variance added to the image increases from left to right.}
