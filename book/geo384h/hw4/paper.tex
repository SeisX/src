\author{Boris Delaunay}
%%%%%%%%%%%%%%%%%%%%%%%
\title{Homework 4}

\begin{abstract}
  This homework has four parts. 
  \begin{enumerate}
  \item Theoretical questions related to interpolation and iterative inversion.
  \item Data interpolation after coordinate transformation.
  \item Irregular data interpolation contest.
  \item Analyzing your own data.
  \end{enumerate}
\end{abstract}

\section{Prerequisites}

Completing the computational part of this homework assignment requires
\begin{itemize}
\item \texttt{Madagascar} software environment available from \\
\url{http://www.ahay.org/}
\item \LaTeX\ environment with \texttt{SEG}\TeX\ available from \\ 
\url{http://www.ahay.org/wiki/SEGTeX}
\end{itemize}
To do the assignment on your personal computer, you need to install
the required environments. Please ask for help if you don't know where
to start.

The homework code is available from the \texttt{Madagascar} repository
by running
\begin{verbatim}
svn co https://github.com/ahay/src/trunk/book/geo384h/hw4
\end{verbatim}

\section{Theoretical part}

You can either write your answers to theoretical questions on paper or
edit them in the file \texttt{hw4/paper.tex}. Please show all the
mathematical derivations that you perform.

\begin{enumerate}

\item The parabolic B-spline $\beta_2(x)$ is a function defined as
 \begin{equation}
   \label{eq:b3} 
   \beta_2(x) = \int\limits_{-\infty}^{\infty} \beta_1(t)\,\beta_0(x-t)\,d t\;,
\end{equation}
where
\begin{equation}
   \label{eq:b1}
   \beta_0(x) = \left\{\begin{array}{lcl} 1 & \quad\mbox{for}\quad & |x| \le 1/2 \\
       0 &\quad \mbox{for}\quad& |x| > 1/2\end{array}\right.
 \end{equation}
and
\begin{equation}
  \label{eq:b2} 
   \beta_1(x) = \int\limits_{-\infty}^{\infty} \beta_0(t)\,\beta_0(x-t)\,d t\;
   = \left\{\begin{array}{lcl} 1-|x| &\quad \mbox{for}\quad& |x| \le 1 \\
       0 & \quad \mbox{for}\quad&  |x| > 1\end{array}\right.
\end{equation}

\begin{enumerate}
\item Find an explicit expression for $\beta_2(x)$.
\item Show that decomposing a continuous data function $d(x)$ into the convolution basis 
  with parabolic B-spines
  \begin{equation}
    \label{eq:basis} 
    d(x) = \sum\limits_k c_k\,\beta_2(x-k)
  \end{equation}
  leads to an interpolation filter of the form
  \begin{equation}
    \label{eq:bz}
    Z^{\sigma} \approx B_2(Z) = \frac{a_0(\sigma)\,Z^{-1} + a_1(\sigma) + a_2(\sigma)\,Z}{b_0\,Z^{-1} + b_1 + b_2\,Z}\;.
  \end{equation}
  Define $a_0(\sigma)$, $a_1(\sigma)$, $a_2(\sigma)$, $b_0$, $b_1$, and $b_2$.
\end{enumerate}

\item The following algorithm finds a solution to
  the least-squares optimization problem $\min
  |\mathbf{F}\,\mathbf{m} - \mathbf{d}|^2$, where $\mathbf{d}$ is
  data, $\mathbf{m}$ is the model we want to estimate, and
  $\mathbf{F}$ is a linear operator that connects them.

 \begin{algorithm}{Conjugate gradients}{\mathbf{F},\mathbf{d},N}
  \mathbf{m \= 0} \\
  \mathbf{r \= - d} \\
  \begin{FOR}{n \= 1, 2, \ldots, N} \\
    \mathbf{g}_m \= \mathbf{F}^T\,\mathbf{r} \\
    \mathbf{g}_r \= \mathbf{F}\,\mathbf{g}_m \\
    \rho \= \mathbf{g}_m^T\,\mathbf{g}_m \\
    \begin{IF}{n = 1} 
      \beta \= 0 
      \ELSE 
      \beta \= \rho/\hat{\rho} 
    \end{IF} \\
    \left[\begin{array}{l}
        \mathbf{s}_m \\
        \mathbf{s}_r
      \end{array}\right] \= 
    \left[\begin{array}{l}
        \mathbf{g}_m \\
        \mathbf{g}_r
      \end{array}\right] + \beta\,
    \left[\begin{array}{l}
        \mathbf{s}_m \\
        \mathbf{s}_r
      \end{array}\right] \\
    \alpha \= - \rho/(\mathbf{s}_r^T\,\mathbf{s}_r) \\
    \left[\begin{array}{l}
        \mathbf{m} \\
        \mathbf{r}
      \end{array}\right] \= 
    \left[\begin{array}{l}
        \mathbf{m} \\
        \mathbf{r}
      \end{array}\right] + \alpha\,
    \left[\begin{array}{l}
        \mathbf{s}_m \\
        \mathbf{s}_r
      \end{array}\right] \\
    \hat{\rho} \= \rho
  \end{FOR} \\        
  \RETURN \mathbf{m}
\end{algorithm}

\begin{enumerate}
\item  In applications, it is often advantageous to apply model
    re-parametrization or \emph{preconditioning}. Suppose that,
  instead of solving for $\mathbf{m}$ directly, you first solve for
  $\mathbf{x}$ such that $\mathbf{m} = \mathbf{P}\,\mathbf{x}$. Show
  how to incorporate the linear preconditioning operator $\mathbf{P}$
  in the algorithm above.
\item Prove that the output of the algorithm after $N$ iterations is
\begin{equation}
\label{eq:msol}
\mathbf{m}_N = \sum\limits_{n=1}^{N} \frac{\mathbf{s}_n\,\mathbf{s}_n^T}{\mathbf{s}_n^T\,\mathbf{F}^T\,\mathbf{F}\,\mathbf{s}_n}\,\mathbf{F}^T\,\mathbf{d}\;,
\end{equation}
where $\mathbf{s}_n$ is the model step at $n$-th iteration.

\end{enumerate}

\end{enumerate}

\section{Interpolation after coordinate transformation}
\inputdir{rotate}

In this exercise, we will use a slice out of a 3-D CT-scan of a
carbonate rock sample, shown in
Figure~\ref{fig:circle}\footnote{Courtesy of Jim Jennings
  (currently at Shell.)}. Notice microfracture channels.

\multiplot{2}{circle,rotate}{width=0.45\textwidth}{Slice of a CT-scan
  of a carbonate rock sample. (a) Original. (b) After clockwise rotation
  by $90^{\circ}$.}

The goal of the exercise is to apply a coordinate transformation to
the original data. A particular transformation that we will study is
coordinate rotation. Figure~\ref{fig:rotate} shows the original slice
rotated by 90 degrees. A 90-degree rotation in this case amounts to
simple transpose. However, rotation by a different angle requires
interpolation from the original grid to the modified grid.

The task of coordinate rotation is accomplished by the C program
\texttt{rotate.c}. Two different methods are implemented: 
nearest-neighbor interpolation and bilinear interpolation.

To test the accuracy of different methods, we can rotate the original
data in small increments and then compare the result of rotating to
$360^{\circ}$ with the original data. Figure~\ref{fig:nearest,linear}
compares the error of the nearest-neighbor and bilinear interpolations
after rotating the original slice in increments of $20^{\circ}$. The
accuracy is comparatively low for small discontinuous features like
microfracture channels.

To improve the accuracy further, we need to employ a longer
filter. One popular choice is \emph{cubic convolution} interpolation,
invented by Robert Keys (a geophysicist, currently at ConocoPhillips).
The cubic convolution filter can be expressed as the
filter \cite[]{keys}
\begin{eqnarray}
\nonumber
Z^{\sigma} \approx C(Z) & = & -\frac{\sigma\,(1-\sigma)^2}{2}\,Z^{-1} + 
\frac{(1-\sigma)\,(2 + 2\,\sigma - 3 \sigma^2)}{2} + \\
&  & \frac{\sigma\,(1 + 4\,\sigma - 3\,\sigma^2)}{2}\,Z - \frac{(1-\sigma)\,\sigma^2}{2}\,Z^2\;.
\label{eq:cubic}
\end{eqnarray}
and is designed to approximate the ideal sinc-function interpolator.

\multiplot{2}{nearest,linear}{width=0.45\textwidth}{Error of different
  interpolation methods computed after full circle rotation in
  increments of 20 degrees. (a) Nearest-neighbor interpolation. (b)
  Bi-linear interpolation.}

\lstset{language=c,numbers=left,numberstyle=\tiny,showstringspaces=false}
\lstinputlisting[frame=single,title=rotate/rotate.c]{rotate/rotate.c}

\lstset{language=python,numbers=left,numberstyle=\tiny,showstringspaces=false}
\lstinputlisting[frame=single,title=rotate/SConstruct]{rotate/SConstruct}

Your task:
\begin{enumerate}
\item Change directory to \texttt{hw4/rotate}
\item Run 
\begin{verbatim}
scons view
\end{verbatim}
to reproduce the figures on your screen.
\item Additionally, you can run
\begin{verbatim}
scons nearest.vpl
\end{verbatim}
and
\begin{verbatim}
scons linear.vpl
\end{verbatim}
to see movies of incremental slice rotation with different methods.
\item Modify the \texttt{rotate.c} program and the \texttt{SConstruct} file to implement 
the cubic convolution interpolation and to compare 
its results with the two other methods.
\item \textbf{EXTRA CREDIT} for implementing an interpolation algorithm, which 
is more accurate than cubic convolution.
\end{enumerate}

\section{Spatial interpolation contest}
\inputdir{invint}

In 1997, the European Communities organized a Spatial Interpolation
Comparison. Many different organizations participated with the results
published in a special issue of the \emph{Journal of Geographic
Information and Decision Analysis} \cite[]{dubois} and a separate
report \cite[]{rain}.

\sideplot{elev}{width=\textwidth}{Digital elevation map of Switzerland.}

The comparison used a dataset from rainfall measurements in
Switzerland on the 8th of May 1986, the day of the Chernobyl disaster.
Figure~\ref{fig:elev} shows the data area: the Digital Elevation Model
of Switzerland with superimposed country's borders.  A total of 467
rainfall measurements were taken that day. A randomly selected subset
of 100 measurements was used as the input data the 1997 Spatial
Interpolation Comparison in order to interpolate other measurements
using different techniques and to compare the results with the known
data. Figure~\ref{fig:raindata} shows the spatial locations of the
selected data samples and the full dataset.

\plot{raindata}{width=\textwidth}{Left: locations of weather stations used as input data in the spatial interpolation contest.
Right: all weather stations locations.}

In this assignment, you will try different techniques of spatial data
interpolation and will participate in the interpolation contest.

\subsection{Delaunay triangulation}

The first technique we are going to try is Delaunay triangulation with
linear interpolation of rainfall values inside each triangle. The
result is shown in Figure~\ref{fig:trian}. Does it succeed in hiding
the acquisition footprint? Figure~\ref{fig:trian-pred} provides a
comparison between interpolated and known data values. It also
indicates the value of the correlation coefficient.

\multiplot{2}{trian,trian-pred}{width=0.45\textwidth}{(a) Rainfall data
interpolated using Delaunay triangulation. (b) Correlation between
interpolated and true data values.}

\subsection{Gradient regularization}

An alternative technique is a solution of the regularized
least-squares optimization problem
\begin{equation}
\label{eq:laplace}
\min\left( |\mathbf{F}\,\mathbf{m} - \mathbf{d}|^2 + \epsilon^2 |\mathbf{R}\,\mathbf{m}|^2\right)\;,
\end{equation}
where $\mathbf{d}$ is irregular data, $\mathbf{m}$ is model estimated
on a regular grid, $\mathbf{F}$ is forward interpolation from the
regular grid to irregular locations, $\epsilon$ is a scaling
parameter, and $\mathbf{R}$ is the regularization operator related to
the inverse of the assumed model covariance. In our experiment,
$\mathbf{R}$ is the finite-difference gradient filter.

\plot{inter0}{width=\textwidth}{Rainfall data
interpolated using regularization with the gradient filter.}

Figure~\ref{fig:inter0} shows the interpolation result after 10 and
100 iterations. 100 iterations are not enough to converge to an
acceptable solution, which is evident from the correlation analysis in
Figure~\ref{fig:inter0-100-pred}.

\sideplot{inter0-100-pred}{width=0.8\textwidth}{Correlation between
  interpolated and true data values for regularization with 100 iterations.}

\subsection{Helical derivative preconditioning}

An alternative to the optimization problem~(\ref{eq:laplace}) is the
problem of minimizing $|\mathbf{x}|^2+|\mathbf{r}|^2$ under the
constraint 
\begin{equation}
\label{eq:precon}
\mathbf{F}\,\mathbf{P}\,\mathbf{x} + \epsilon\,\mathbf{r} = \mathbf{d}\;.
\end{equation}
The model $\mathbf{m}$ is defined by
$\mathbf{m}=\mathbf{P}\,\mathbf{x}$, and the \emph{preconditioning}
operator $\mathbf{P}$ is related to the regularization operator
$\mathbf{R}$ according to
\begin{equation}
\label{eq:covar}
\mathbf{P}\,\mathbf{P}^T = \left(\mathbf{R}^T\,\mathbf{R}\right)^{-1}\;.        
\end{equation}

The autocorrelation of the gradient filter $\mathbf{R}^T\,\mathbf{R}$
is the Laplacian filter, which can be represented as a five-point polynomial
\begin{equation}
\label{eq:lap2}
L_2(Z_1,Z_2) = 4 - Z_1 - Z_1^{-1} - Z_2 - Z_2^{-1}\;.
\end{equation} 
To invert the Laplacian filter, we can put on a helix, where it takes
the form
\begin{equation}
\label{eq:lap1}
L_H(Z) = 4 - Z - Z^{-1} - Z^{N_1} - Z^{-N_1}\;,
\end{equation} 
and factor it into two minimum-phase parts $L_H(Z) = D(Z)\,D(1/Z)$
using the Wilson-Burg algorithm \cite[]{burg}. 

\plot{inter1}{width=\textwidth}{Rainfall data
interpolated using preconditioning with the inverse helical filter.}

Figure~\ref{fig:inter1} shows the interpolation result using
conjugate-gradient optimization with equation~(\ref{eq:precon}) after
10 and 100 iterations. The corresponding correlation analysis is shown
in Figure~\ref{fig:inter1-100-pred}.

\sideplot{inter1-100-pred}{width=0.8\textwidth}{Correlation between
  interpolated and true data values for preconditioning with 100
  iterations.}

\subsection{Shaping regularization}

For the shaping regularization approach, we are going to try the simple iteration
\begin{equation}
\label{eq:mshape}
\mathbf{m}_{n+1} = \mathbf{S}_m\left[\mathbf{m}_{n} + \tilde{\mathbf{m}} -  \mathbf{B\,F\,m}_n\right]\;,
\end{equation}
where the forward operator $\mathbf{F}$ is bilinear interpolation, the
backward operator $\mathbf{B}$ is interpolation by Delaunay
triangulation, and the model shaping operator $\mathbf{S}_m$ is
triangle smoothing.

Figure~\ref{fig:shaping} shows the interpolation result using
10 shaping iterations. The corresponding correlation analysis is shown
in Figure~\ref{fig:shaping10-pred}.

\sideplot{shaping}{width=\textwidth}{Rainfall data
interpolated using shaping regularization.}

\sideplot{shaping10-pred}{width=0.8\textwidth}{Correlation between
  interpolated and true data values for shaping regularization with 10
  iterations.}

Your task:
\begin{enumerate}
\item Change directory to \texttt{hw4/invint}
\item Run 
\begin{verbatim}
scons view
\end{verbatim}
to reproduce the figures on your screen.
\item Modify the \texttt{SConstruct} file to accomplish the following
  tasks:
\begin{enumerate}
\item Find out 
the number of conjugate-gradient iterations needed for the gradient regularization method to achieve a result 
 comparable with the preconditioning method.
\item Find out 
the number of iterations~(\ref{eq:mshape}) needed for the shaping regularization method to achieve a result 
 comparable with the preconditioning method.
\end{enumerate}
\item What can you conclude about the four methods used in this comparison?
\item \textbf{EXTRA CREDIT} Participate in the Spatial Interpolation Contest. Find and
implement a method that would provide a better interpolation of the
missing values than either of the methods we tried so far. You can
change any of the parameters in the existing methods or write your own
program but you can use only the 100 original data points as input.
\end{enumerate}

\lstset{language=c,numbers=left,numberstyle=\tiny,showstringspaces=false}
\lstinputlisting[frame=single,title=invint/invint.c]{invint/invint.c}

\lstset{language=python,numbers=left,numberstyle=\tiny,showstringspaces=false}
\lstinputlisting[frame=single,title=invint/SConstruct]{invint/SConstruct}

\section{Your own data}

Your final task is to apply one of the data analysis techniques of the
previous sections (data interpolation by coordinate transformation or
scattered data gridding) to your own data:
\begin{enumerate}
\item Select a dataset suitable for this application.
\item Apply one of the algorithms of the previous two sections and choose appropriate parameters.
\item Include the results in your homework.
\end{enumerate}

\section{Completing the assignment}

\begin{enumerate}
\item Change directory to \texttt{hw4}.
\item Edit the file \texttt{paper.tex} in your favorite editor and change the
  first line to have your name instead of Delaunay's.
\item Run
\begin{verbatim}
sftour scons lock
\end{verbatim}
to update all figures.
\item Run
\begin{verbatim}
sftour scons -c
\end{verbatim}
to remove intermediate files.
\item Run
\begin{verbatim}
scons pdf
\end{verbatim}
to create the final document.
\item Submit your result (file \texttt{paper.pdf}) on paper or by
e-mail.
\end{enumerate}

\bibliographystyle{seg}
\bibliography{hw4}
